{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction to Machine Learning durability and mointoring "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. ML lifecycle and what can go wrong in production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML lifecycle \n",
    "- Data preparation\n",
    "- Feature engineering\n",
    "- Model training\n",
    "- Model evaluation\n",
    "- model deployment \n",
    "\n",
    "After performing some evaluations like EDA and model testing and evaluation and then selecting the best model, we deploy the model to production but the evaluation process does not stop there. We need to monitor the model in production to make sure it is performing as expected. So the last step would be:\n",
    "- Performance monitoring that targets the model training and feature engineeering steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What can go worong in production?\n",
    "Once the model is deployes it starts bringing some issues like:\n",
    "- **Training-serving skew:** The model performance goes down when the training data is very different from the production data.\n",
    "- **Data quality issues:** \n",
    "    - *Data processing issues:* it includes broken pipelines, insrastructure updates (software tooles and hardware components), wrong source ...\n",
    "    - *Data schema changes:* upstream system (server), external APIs, catalog update..\n",
    "    - *Data loss*\n",
    "- **Broken upstream models:** it often affects the chain of ML models operators in production. If one of them goes wrong the chaine will break.\n",
    "- **Concept drift:**  it occurs when the relationship betwwen the inputs and outputs changes overtime (eg. new user behavior).\n",
    "- **Data drift:** it involves changes in the data distribution itself (eg. population change or product changes).\n",
    "- **Underperforming segments:** it occurs when the model performs  deffirently on diverse data segments (eg. A medical diagnostic model might perform well overall but fails to perform for a specific age group).\n",
    "- **Adversarial adaptation:** models might face adversarial attacks that are designed to fool the model (eg. making small changes to the images to mislead an animal classification model). It mainly occurs in Neural networks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. ML monitoring and observability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine learning model monitoring \n",
    "It is a series of techniques to track and analyze the performance of ML model sin production. It helps measure omgoing model quality, warn about potential issues and resolve them in time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitoring use cases\n",
    "- **Models on production:** it helps to monitor the model performance and detect issues in time.\n",
    "- **Models in shadow deployment:** Shadow modes means tracking the behavior of a candidate model in production but without affecting the production traffic. \n",
    "- **During A/B testing:** This technique is used to compare the performance of two candidate models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenges of ML monitoring\n",
    "- **Software VS ML monitoring:** which includes tracking of health metrics such as uptime, memory usage and latency. Ml monitoring adds two extra layers which are **Data health** and **Model health**.\n",
    "- **Selecting the right metric:** It can be challenging due to various factors such as class imbalance, data distribution, data noisness..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ml Monitoring VS Observability\n",
    "- **ML monitoring:**  ML monitoring involves tracking specific model metrics and detect issues over time.\n",
    "- **ML Observability:** It focuses on gaining insights into the behaviour and performance of the system.\n",
    "- **Key difference:** ML monitoring is specific to ML models and their performance while ML observability extends to the system level monitoring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML monitoring and observability importance\n",
    "They mainly help:\n",
    "- **Detect issues**\n",
    "- **Find root causes**\n",
    "- **Understand the model behaviour**\n",
    "- **Trigger actions:** such as fallback or automatic retraining\n",
    "- **Document ML model performance**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. ML monitoring metrics. What exactly can you monitor?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ml based service system goes beyond ML models. Monitoring its performance involves different group of metrics:\n",
    "- **Software system health:** it includes latency, error rate, memory usage, disk usage ...\n",
    "- **Data quality and data integrity:** its goal is to ensure the stability of the data pipeline and dealing with missing values, type mismatches, range violations for important features\n",
    "- **ML model quality and relevance:** its goal is to ensure that the model is working as expected. It includes standard metrics (such as precision, accuracy and MAE), Use-case specific quality metrics (such as bias and fairness), proxy metrics (such as input data drift).\n",
    "- **Buisness KPIs:** Measure the impact of the model on the buisness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Key considerations for ML monitoring setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching ML monitoring setup and use case\n",
    "The complexity of the system monitoring should be aligned with the complexity of the deployment and operations of ML service. Some factors to consider:\n",
    "- **ML service implementation**\n",
    "- **Feedback loop and environmental stability:** Feedback loop involves ontinually collecting and using feedback to enhance the system's performance while environmental stability ensures that the system remains reliable and effective in its operating environment. They both influence the choice of metrics.\n",
    "- **Service criticality:** It involves evaluating the impact of service's downtime, errors or degraded performance (eg. healthcare, finance, transportation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference dataset\n",
    "A Reference dataset is a dataset that is used as a point of reference for comparing the performance of ML systems. It can can be used also as a baseline for the drift comparaison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom metrics\n",
    "Custom metrics are metrics that are specific to the use case and are not available in the standard metrics. They are used to measure the performance of the model in a specific use case. They can be:\n",
    "- **Use-case specific model quality metrics (eg. lift-10% for churn prediction)** \n",
    "- **Heuristics**\n",
    "- **Buisness quality metrics**\n",
    "- **Custom drift detection methods**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5. ML Monitoring Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitoring backend\n",
    "- **Batch ML Monitoring:** it is set up to run periodically (eg. daily, weekly, monthly) or on a trigger (eg. when a new batch data comes). Some metrics are calculated in batch mode such as data drift.\n",
    "- **Near real-time (streaming) ML monitoring:** This architecture is suited for ML models that requires immediate or real-near-time monitoring. The data is sent from ML service to ML monitoring system directly.\n",
    "- **Ad Hoc Monitoring:** It uses python scripts to monitor the model performance. It is used for one-time monitoring or for monitoring a specific use case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitoring frontend\n",
    "- **No User Interface:** Collecting the data without visualizing it and log netrics into the database.\n",
    "- **One-off reports:** Create visualizations and reports as needed based on the model logs.\n",
    "- **BI Systems:** Reuse existing BI systems or software monitoring systems.\n",
    "- **Deicated ML monitoring:** Set up a dedicated ML monitoring system that is designed to give an overview of all the ML models and datasets and provide an ongoing updated view of metrics."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
